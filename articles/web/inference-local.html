<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Inference: Local mfdr ‚Ä¢ ncvreg</title>
<script src="../../lightswitch.js"></script><script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../../deps/headroom-0.11.0/headroom.min.js"></script><script src="../../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../../deps/search-1.0.0/fuse.min.js"></script><script src="../../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Inference: Local mfdr">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../../index.html">ncvreg</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">3.15.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../../index.html"><span class="fa fa-home fa-lg"></span></a></li>
<li class="nav-item"><a class="nav-link" href="../../articles/web/getting-started.html">Getting started</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-learn-more" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Learn more</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-learn-more">
<li><a class="dropdown-item" href="../../articles/web/models.html">Models</a></li>
    <li><a class="dropdown-item" href="../../articles/web/penalties.html">Penalties</a></li>
    <li><a class="dropdown-item" href="../../articles/web/adaptive-rescaling.html">Standardization</a></li>
    <li><a class="dropdown-item" href="../../articles/web/inference-mfdr.html">Inference: Marginal false discovery rates</a></li>
    <li><a class="dropdown-item" href="../../articles/web/inference-local.html">Inference: Local mfdr</a></li>
    <li><a class="dropdown-item" href="../../articles/web/other-cv-criteria.html">Other CV criteria</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../../reference/index.html">Functions</a></li>
<li class="nav-item"><a class="nav-link" href="../../news/index.html">News</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/pbreheny/ncvreg/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Inference: Local mfdr</h1>
                        <h4 data-toc-skip class="author">Ryan Miller and
Patrick Breheny</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/pbreheny/ncvreg/blob/ncvreg_3.15.0/vignettes/web/inference-local.rmd" class="external-link"><code>vignettes/web/inference-local.rmd</code></a></small>
      <div class="d-none name"><code>inference-local.rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="local-false-discovery-rates">Local False Discovery Rates<a class="anchor" aria-label="anchor" href="#local-false-discovery-rates"></a>
</h2>
<p>Classical, single-feature, hypothesis testing approaches rely upon
tail-area probabilies, or the probability that a test statistic,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>,
exceeds a certain value. In contrast, <em>local approaches</em> like <a href="https://arxiv.org/abs/1809.05497" class="external-link">local mfdr</a> base inference on
that feature‚Äôs specific value value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>
without considering the hypothetical possibility of more extreme
results.</p>
<p>Local false discovery rates are a Bayesian idea that can be
implemented in large-scale testing situations by using empirical Bayes
methods to obtain estimates of:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>H</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>z</mi><mi>j</mi></msub><mo>=</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex"> Pr(H_{0j} | z_j = z)</annotation></semantics></math></p>
<p>The probability of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>j</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup><annotation encoding="application/x-tex">j^{th}</annotation></semantics></math>
null hypothesis being true, conditional upon the exact value of the
observed test statistic
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>z</mi><mi>j</mi></msub><annotation encoding="application/x-tex">z_j</annotation></semantics></math>.
This probability is defined as the <em>local false discovery rate</em>
for the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>j</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup><annotation encoding="application/x-tex">j^{th}</annotation></semantics></math>
feature.</p>
</div>
<div class="section level2">
<h2 id="estimation">Estimation<a class="anchor" aria-label="anchor" href="#estimation"></a>
</h2>
<p>Using Bayes‚Äô rule, we have</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>r</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>H</mi><mrow><mn>0</mn><mi>j</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>z</mi><mi>j</mi></msub><mo>=</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><msub><mi>œÄ</mi><mn>0</mn></msub><msub><mi>f</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><msub><mi>œÄ</mi><mn>0</mn></msub><msub><mi>f</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>‚àí</mo><msub><mi>œÄ</mi><mn>0</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>f</mi><mn>1</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex">Pr(H_{0j} | z_j = z)  = \frac{\pi_0 f_0(z)}{\pi_0f_0(z) + (1 - \pi_0) f_1(z)}, </annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>œÄ</mi><mn>0</mn></msub><annotation encoding="application/x-tex">\pi_0</annotation></semantics></math>
is the prior probability of a true null hypothesis for the collection of
tests,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mn>0</mn></msub><annotation encoding="application/x-tex">f_0</annotation></semantics></math>
is the theoretical density of test statistics under the null, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mn>1</mn></msub><annotation encoding="application/x-tex">f_1</annotation></semantics></math>
is the density of non-null test statistics.</p>
<p>A variety of estimators are possible depending on how one goes about
estimating this mixture of densities. One simple approach, currently
used by <code>ncvreg</code>, is to set
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÄ</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\pi_0 = 1</annotation></semantics></math>
and to avoid estimating
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mn>1</mn></msub><annotation encoding="application/x-tex">f_1</annotation></semantics></math>
by estimating only the marginal density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f(z)</annotation></semantics></math>
using a kernel density approach. Thus:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mtext mathvariant="normal">mfdr</mtext><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mrow><msub><mi>œÄ</mi><mn>0</mn></msub><msub><mi>f</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mover><mi>f</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mi>.</mi></mrow><annotation encoding="application/x-tex"> \widehat{\text{mfdr}}(z) = \frac{\pi_0 f_0(z)}{\hat{f}(z)}.</annotation></semantics></math>
In situations where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>0</mn></msub><mrow><mo stretchy="true" form="prefix">(</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>&gt;</mo><mover><mi>f</mi><mo accent="true">ÃÇ</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mi>z</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_0(z) &gt; \hat{f}(z)</annotation></semantics></math>,
local mfdr estimates are capped at 1.</p>
</div>
<div class="section level2">
<h2 id="test-statistics">Test Statistics<a class="anchor" aria-label="anchor" href="#test-statistics"></a>
</h2>
<p>For each predictor, <code><a href="../../reference/mfdr.html">mfdr()</a></code> constructs a test statistic
based upon the mathematical conditions necessary for that variable to
enter the model characterized by a given value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œª</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>.
For linear regression models, these statistics have the form:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>j</mi></msub><mo>=</mo><mfrac><mrow><msubsup><mi>ùê±</mi><mi>j</mi><mi>T</mi></msubsup><mrow><mo stretchy="true" form="prefix">(</mo><mi>ùê≤</mi><mo>‚àí</mo><msub><mi>ùêó</mi><mrow><mo>‚àí</mo><mi>j</mi></mrow></msub><msub><mi>ùõÉ</mi><mrow><mo>‚àí</mo><mi>j</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><mi>œÉ</mi><mi>/</mi><msqrt><mi>n</mi></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">  z_j = \frac{\mathbf{x}_j^T(\mathbf{y} - \mathbf{X}_{-j}\mathbf{\beta}_{-j})}{\sigma/\sqrt{n}} </annotation></semantics></math>
The subscript
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>‚àí</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">-j</annotation></semantics></math>
indicates the removal of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>j</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup><annotation encoding="application/x-tex">j^{th}</annotation></semantics></math>
predictor. For logistic and Cox regression models, these statistics have
the form:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>j</mi></msub><mo>=</mo><mfrac><mrow><msub><mi>u</mi><mi>j</mi></msub><mo>+</mo><msub><mi>v</mi><mi>j</mi></msub><msub><mi>Œ≤</mi><mi>j</mi></msub></mrow><msqrt><msub><mi>v</mi><mi>j</mi></msub></msqrt></mfrac></mrow><annotation encoding="application/x-tex">  z_j = \frac{u_j+ v_j\beta_j}{\sqrt{v_j}} </annotation></semantics></math>
Here
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>u</mi><mi>j</mi></msub><annotation encoding="application/x-tex">u_j</annotation></semantics></math>
is the unpenalized score function (ie: the first derivative, with
respect to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Œ≤</mi><mi>j</mi></msub><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math>,
of the log-likelihood), and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mi>j</mi></msub><annotation encoding="application/x-tex">v_j</annotation></semantics></math>
is the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>j</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup><annotation encoding="application/x-tex">j^{th}</annotation></semantics></math>
diagonal element of the unpenalized Hessian matrix (ie: the second
derivative of the log-likelihood)</p>
<p>Under feature independence, each of these statistics will follow a
standard normal distribution under the null hypothesis of that predictor
being independent of the current model‚Äôs residuals. Despite being
derived under independence, <code>mfdr</code> tends to be accurate under
mild to moderate dependence structures, see <a href="https://arxiv.org/abs/1809.05497" class="external-link">Miller and Breheny (2018)</a>
for additional details.</p>
</div>
<div class="section level2">
<h2 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a>
</h2>
<p>Local mfdr estimates can be obtained via the <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code>
function:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/ncvreg.html">ncvreg</a></span><span class="op">(</span><span class="va">Prostate</span><span class="op">$</span><span class="va">X</span>, <span class="va">Prostate</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit</span>, lambda <span class="op">=</span> <span class="fl">0.07</span>,  number <span class="op">=</span> <span class="cn">Inf</span><span class="op">)</span></span>
<span><span class="co"># MCP-penalized linear regression with n=97, p=8</span></span>
<span><span class="co"># At lambda=0.0700:</span></span>
<span><span class="co"># -------------------------------------------------</span></span>
<span><span class="co">#   Features satisfying criteria       : 8</span></span>
<span><span class="co">#   Average mfdr among chosen features : 0.592</span></span>
<span><span class="co"># </span></span>
<span><span class="co">#          Estimate       z     mfdr Selected</span></span>
<span><span class="co"># lcavol   0.530785  8.7704  &lt; 1e-04        *</span></span>
<span><span class="co"># svi      0.684680  3.9737 0.010695        *</span></span>
<span><span class="co"># lweight  0.622144  3.7369 0.026104        *</span></span>
<span><span class="co"># lbph     0.038452  1.5077 0.901245        *</span></span>
<span><span class="co"># age     -0.004084 -1.2704 0.926945        *</span></span>
<span><span class="co"># pgg45    0.000000  0.8675 0.951263         </span></span>
<span><span class="co"># gleason  0.000000  0.7467 0.955590         </span></span>
<span><span class="co"># lcp      0.000000 -0.2711 0.964801</span></span></code></pre></div>
<p>The argument <code>number = Inf</code> requests mfdr estimates for
all features, regardless of whether or not they are active in the
specified model. These estimates can be understood by studying the
theoretical null and empirically estimated mixture densities for these
data:</p>
<p><img src="inference-local_files/figure-html/unnamed-chunk-2-1.png" width="672"></p>
<p>The feature <code>lcavol</code> has an extremely small estimated mfdr
with a statistic of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mn>8.77</mn></mrow><annotation encoding="application/x-tex">z = 8.77</annotation></semantics></math>,
the origin of this estimate is apparent when examining the ratio between
the null and mixture densities at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mn>8.88</mn></mrow><annotation encoding="application/x-tex">z = 8.88</annotation></semantics></math>.
In contrast, the feature <code>lbph</code> has a estimated mfdr of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0.94</mn><annotation encoding="application/x-tex">0.94</annotation></semantics></math>
with a statistic of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mn>1.51</mn></mrow><annotation encoding="application/x-tex">z = 1.51</annotation></semantics></math>,
this estimated is explained by the null and mixture densities being
similar near
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mn>1.51</mn></mrow><annotation encoding="application/x-tex">z = 1.51</annotation></semantics></math>.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Patrick Breheny, Ryan Miller, Logan Harris.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
