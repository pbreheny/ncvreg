---
title: "Models"
author: "Patrick Breheny"
output:
  rmarkdown::html_vignette:
    css: vignette.css
vignette: >
  %\VignetteIndexEntry{Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
library(ncvreg)
knitr::opts_knit$set(aliases=c(h = 'fig.height', w = 'fig.width'))
knitr::opts_chunk$set(comment="#", collapse=TRUE, cache=FALSE, tidy=FALSE)
knitr::knit_hooks$set(small.mar = function(before, options, envir) {
  if (before) par(mar = c(4, 4, .1, .1))
})
```

<div style='text-align: center; font-size: 200%; font-weight: 700; margin: 20pt;'><i class="fa fa-wrench"></i> Under construction <i class="fa fa-wrench"></div>

`ncvreg` fits models that fall into the penalized likelihood framework.  Rather than estimating $\bb$ by maximizing the likelihood, in this framework we estimate $\bb$ by minimizing the objective function
$$
Q(\bb|\X, \y) = L(\bb|\X,\y) + P_\lam(\bb),
$$
where $L(\bb|\X,\y)$ is the loss (typically, the negative log-likelihood), $P_\lam(\bb)$ is the penalty, and $\lam$ is a regularization parameter that controls the tradeoff between the two components.  This article describes the different loss models available in `ncvreg`; see [penalties](penalties.html) for more information on the different penalties available.

# Gaussian (linear regression)

Here the loss function is simply the squared error loss:
$$
L(\bb|\X,\y) = \norm{\y-\X\bb}_2^2
$$
this loss is the negative log-likelihood if the outcome $\y$ follows a normal distribution with constant variance and mean given by $\X\bb$.

In the `Prostate` data packaged with `ncvreg`, the response is the prostate specific antigen (PSA), measured on the log scale, and follows an approximate normal distribution; see `?Prostate` for more information on the data set.  Loading this data set into R,

```{r}
data(Prostate)
X <- Prostate$X
y <- Prostate$y
```

Fit the model (default is linear regression with MCP penalty):

```{r}
fit <- ncvreg(X, y)
```

A solution path:

```{r fit-linear, h=4, w=4, small.mar=TRUE}
plot(fit)
```

And a summary:

```{r}
summary(fit, lambda=0.02)
```

Carry out cross-validation:

```{r}
cvfit <- cv.ncvreg(X, y)
```

Cross-validation plot:

```{r cvfit-linear, h=4, w=4}
plot(cvfit)
```

And a summary:

```{r}
summary(cvfit)
```

# Binomial (logistic regression)

# Poisson

# Cox proportional hazards
