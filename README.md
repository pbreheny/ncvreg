
<!-- README.md was generated by README.rmd.  Do not edit by hand. -->

[![version](http://www.r-pkg.org/badges/version/ncvreg)](https://cran.r-project.org/package=ncvreg)
[![downloads](http://cranlogs.r-pkg.org/badges/ncvreg)](https://cran.r-project.org/package=ncvreg)
[![codecov.io](https://codecov.io/github/pbreheny/ncvreg/coverage.svg?branch=master)](https://codecov.io/github/pbreheny/ncvreg?branch=master)
[![Travis build
status](https://travis-ci.org/pbreheny/breheny.svg?branch=master)](https://travis-ci.org/pbreheny/breheny)

# Regularization Paths for SCAD and MCP Penalized Regression Models

`ncvreg` is an R package for fitting regularization paths for linear
regression, GLM, and Cox regression models using lasso or nonconvex
penalties, in particular the minimax concave penalty (MCP) and smoothly
clipped absolute deviation (SCAD) penalty, with options for additional
L<sub>2</sub> penalties (the “elastic net” idea). Utilities for carrying
out cross-validation as well as post-fitting visualization,
summarization, inference, and prediction are also provided.

The [ncvreg site](http://pbreheny.github.io/ncvreg/index.html) focuses
mainly on illustrating the usage and syntax of `ncvreg`. For more on the
algorithms used by `ncvreg`, see the original article:

  - [Breheny P and Huang J (2011). Coordinate descent algorithms for
    nonconvex penalized regression, with applications to biological
    feature selection. *Annals of Applied Statistics*, 5:
    232–253](http://myweb.uiowa.edu/pbreheny/pdf/Breheny2011.pdf)

For more about the marginal false discovery rate idea used for
post-selection inference, see

  - [Breheny P (2019). Marginal false discovery rates for penalized
    regression models. *Biostatistics*, **20**:
    299-314](https://dx.doi.org/10.1093/biostatistics/kxy004)

## Installation

`ncvreg` is on CRAN, so it can be installed via:

``` r
install.packages("ncvreg")
```

## Brief introduction

Given a design matrix `X` and response vector `y`, we can fit a
penalized regression model via:

``` r
fit <- ncvreg(X, y)
```

By default, `ncvreg` fits a linear regression model with a minimax
concave penalty (MCP). For more detail on other types of models
available, see [here](articles/web/models.html). For more detail on
other types of penalties available, see
[here](articles/web/penalties.html).

Fitting a penalized regression model produces a path of coefficients,
which we can plot
with

``` r
plot(fit)
```

<img src="man/figures/plot-1.png" style="display: block; margin: auto;" />

Notice that variables enter the model one at a time, and that at any
given value of λ, several coefficients are zero. To see what the
coefficients are, we could use the `coef` function:

``` r
coef(fit, lambda=0.05)
# (Intercept)      lcavol     lweight         age        lbph         svi 
#  0.35121089  0.53178994  0.60389694 -0.01530917  0.08874563  0.67256096 
#         lcp     gleason       pgg45 
#  0.00000000  0.00000000  0.00168038
```

The `summary` method can be used for post-selection inference:

``` r
summary(fit, lambda=0.05)
# MCP-penalized linear regression with n=97, p=8
# At lambda=0.0500:
# -------------------------------------------------
#   Nonzero coefficients         :   6
#   Expected nonzero coefficients:   2.54
#   Average mfdr (6 features)    :   0.424
# 
#         Estimate      z     mfdr Selected
# lcavol   0.53179  8.880  < 1e-04        *
# svi      0.67256  3.945 0.010189        *
# lweight  0.60390  3.666 0.027894        *
# lbph     0.08875  1.928 0.773014        *
# age     -0.01531 -1.788 0.815269        *
# pgg45    0.00168  1.160 0.917570        *
```

In this case, it would appear that `lcavol`, `svi`, and `lweight` are
clearly associated with the response, even after adjusting for the other
variables in the model, while `lbph`, `age`, and `pgg45` may be false
positives selected simply by chance.

Typically, one would carry out cross-validation for the purposes of
assessing the predictive accuracy of the model at various values of λ:

``` r
cvfit <- cv.ncvreg(X, y)
plot(cvfit)
```

<img src="man/figures/cvplot-1.png" style="display: block; margin: auto;" />

The value of λ that minimizes the cross-validation error is given by
`cvfit$lambda.min`, which in this case is 0.017. Applying `coef` to the
output of `cv.ncvreg` returns the coefficients at that value of λ:

``` r
coef(cvfit)
#  (Intercept)       lcavol      lweight          age         lbph          svi 
#  0.494154801  0.569546027  0.614419811 -0.020913467  0.097352536  0.752397339 
#          lcp      gleason        pgg45 
# -0.104959403  0.000000000  0.005324465
```

Predicted values can be obtained via `predict`, which has a number of
options:

``` r
predict(cvfit, X=head(X))     # Prediction of response for new observations
#         1         2         3         4         5         6 
# 0.8304040 0.7650906 0.4262072 0.6230117 1.7449492 0.8449595
predict(cvfit, type="nvars")  # Number of nonzero coefficients
# 0.01695 
#       7
predict(cvfit, type="vars")   # Identity of the nonzero coefficients
#  lcavol lweight     age    lbph     svi     lcp   pgg45 
#       1       2       3       4       5       6       8
```

Note that the original fit (to the full data set) is returned as
`cvfit$fit`; it is not necessary to call both `ncvreg` and `cv.ncvreg`
to analyze a data set. For example, `plot(cvfit$fit)` will produce the
same coefficient path plot as `plot(fit)` above.
